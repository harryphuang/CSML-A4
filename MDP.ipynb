{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65db0e5e",
   "metadata": {},
   "source": [
    "Frozen Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81143b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map, FrozenLakeEnv\n",
    "import glob\n",
    "from hiive.mdptoolbox.mdp import ValueIteration, PolicyIteration, QLearning\n",
    "from hiive.mdptoolbox.example import forest\n",
    "# import hiive_mdptoolbox.example\n",
    "# import hiive_mdptoolbox\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "np.random.seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "089650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "twenty = generate_random_map(20)\n",
    "MAPS = {\n",
    "    \"20x20\": twenty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "624708c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(env, policy, gamma, render = True):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        obs, reward, done , _ = env.step(int(policy[obs]))\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def evaluate_policy(env, policy, gamma , n = 100):\n",
    "    scores = [run_process(env, policy, gamma, False) for _ in range(n)]\n",
    "    return np.mean(scores)\n",
    "\n",
    "def get_policy(env,v, gamma):\n",
    "    policy = np.zeros(env.nS)\n",
    "    for s in range(env.nS):\n",
    "        q_sa = np.zeros(env.nA)\n",
    "        for a in range(env.nA):\n",
    "            q_sa[a] = sum([p * (r + gamma * v[s_]) for p, s_, r, _ in  env.P[s][a]])\n",
    "        policy[s] = np.argmax(q_sa)\n",
    "    return policy\n",
    "\n",
    "def compute_policy(env, policy, gamma):\n",
    "    v = np.zeros(env.nS)\n",
    "    eps = 1e-5\n",
    "    while True:\n",
    "        prev_v = np.copy(v)\n",
    "        for s in range(env.nS):\n",
    "            policy_a = policy[s]\n",
    "            v[s] = sum([p * (r + gamma * prev_v[s_]) for p, s_, r, is_done in env.P[s][policy_a]])\n",
    "        if (np.sum((np.fabs(prev_v - v))) <= eps):\n",
    "            break\n",
    "    return v\n",
    "\n",
    "def run_policy_iteration(env, gamma):\n",
    "    policy = np.random.choice(env.nA, size=(env.nS))  \n",
    "    max_iters = 200000\n",
    "    desc = env.unwrapped.desc\n",
    "    for i in range(max_iters):\n",
    "        old_policy_v = compute_policy(env, policy, gamma)\n",
    "        new_policy = get_policy(env,old_policy_v, gamma)\n",
    "        if (np.all(policy == new_policy)):\n",
    "            k=i+1\n",
    "            break\n",
    "        policy = new_policy\n",
    "    return policy,k\n",
    "\n",
    "def run_value_iteration(env, gamma):\n",
    "    v = np.zeros(env.nS)  # initialize value-function\n",
    "    max_iters = 100000\n",
    "    eps = 1e-20\n",
    "    desc = env.unwrapped.desc\n",
    "    for i in range(max_iters):\n",
    "        prev_v = np.copy(v)\n",
    "        for s in range(env.nS):\n",
    "            q_sa = [sum([p*(r + gamma*prev_v[s_]) for p, s_, r, _ in env.P[s][a]]) for a in range(env.nA)] \n",
    "            v[s] = max(q_sa)\n",
    "        if (np.sum(np.fabs(prev_v - v)) <= eps):\n",
    "            k=i+1\n",
    "            break\n",
    "    return v,k\n",
    "\n",
    "def show_policy_map(title, policy, map_desc, color_map, direction_map):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, xlim=(0, policy.shape[1]), ylim=(0, policy.shape[0]))\n",
    "    font_size = 'x-large'\n",
    "    if policy.shape[1] > 16:\n",
    "        font_size = 'small'\n",
    "    plt.title(title)\n",
    "    for i in range(policy.shape[0]):\n",
    "        for j in range(policy.shape[1]):\n",
    "            y = policy.shape[0] - i - 1\n",
    "            x = j\n",
    "            p = plt.Rectangle([x, y], 1, 1)\n",
    "            p.set_facecolor(color_map[map_desc[i,j]])\n",
    "            ax.add_patch(p)\n",
    "\n",
    "            text = ax.text(x+0.5, y+0.5, direction_map[policy[i, j]], weight='bold', size=font_size,\n",
    "                           horizontalalignment='center', verticalalignment='center', color='w')\n",
    "            \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.xlim((0, policy.shape[1]))\n",
    "    plt.ylim((0, policy.shape[0]))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(title+str('.png'))\n",
    "    plt.close()\n",
    "\n",
    "    return (plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "797c1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Frozen_Lake(option):\n",
    "    # 0 = left; 1 = down; 2 = right;  3 = up\n",
    "    size = 4\n",
    "    if (option == \"4x4\"):\n",
    "        environment  = 'FrozenLake-v1'\n",
    "        env = gym.make(environment)\n",
    "        size = 4\n",
    "    else:\n",
    "        env = FrozenLakeEnv(desc=MAPS[\"20x20\"])\n",
    "        size = 20\n",
    "    env = env.unwrapped\n",
    "    desc = env.unwrapped.desc\n",
    "    time_array=[0]*10\n",
    "    gamma_arr=[0]*10\n",
    "    iters=[0]*10\n",
    "    list_scores=[0]*10\n",
    "\n",
    "    \n",
    "    ### POLICY ITERATION ####\n",
    "    print('POLICY ITERATION WITH FROZEN LAKE ' + option)\n",
    "    for i in range(0,10):\n",
    "        st=time.time()\n",
    "        best_policy,k = run_policy_iteration(env, gamma = (i+0.5)/10)\n",
    "        scores = evaluate_policy(env, best_policy, gamma = (i+0.5)/10)\n",
    "        plot = show_policy_map('Frozen Lake  ' + option + ' Policy Map Iteration '+ str(i) + ' (Policy Iteration) ' + 'i: '+ str(i),best_policy.reshape(size,size),desc,colors(),directions())\n",
    "        end=time.time()\n",
    "        gamma_arr[i]=(i+0.5)/10\n",
    "        list_scores[i]=np.mean(scores)\n",
    "        iters[i] = k\n",
    "        time_array[i]=end-st\n",
    "    \n",
    "    # print('Frozen Lake ' + option + ' - Policy Iteration')\n",
    "    # print(list_scores)\n",
    "    \n",
    "    plt.plot(gamma_arr, time_array)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.title('Frozen Lake ' + option + '- Policy Iteration - Execution Time Analysis')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(gamma_arr,list_scores)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.ylabel('Average Rewards')\n",
    "    plt.title('Frozen Lake ' + option + ' - Policy Iteration - Reward Analysis')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(gamma_arr,iters)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.ylabel('Iterations to Converge')\n",
    "    plt.title('Frozen Lake ' + option + ' - Policy Iteration - Convergence Analysis')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    ### VALUE ITERATION ###\n",
    "    print('VALUE ITERATION WITH FROZEN LAKE ' + option)\n",
    "    best_vals=[0]*10\n",
    "    for i in range(0,10):\n",
    "        st=time.time()\n",
    "        best_value,k = run_value_iteration(env, gamma = (i+0.5)/10)\n",
    "        policy = get_policy(env,best_value, gamma = (i+0.5)/10)\n",
    "        policy_score = evaluate_policy(env, policy, gamma=(i+0.5)/10, n=1000)\n",
    "        gamma = (i+0.5)/10\n",
    "        plot = show_policy_map('Frozen Lake  ' + option + ' Policy Map Iteration '+ str(i) + ' (Value Iteration) ' + 'Gamma: '+ str(gamma),policy.reshape(size,size),desc,colors(),directions())\n",
    "        end=time.time()\n",
    "        gamma_arr[i]=(i+0.5)/10\n",
    "        iters[i]=k\n",
    "        best_vals[i] = best_value\n",
    "        list_scores[i]=np.mean(policy_score)\n",
    "        time_array[i]=end-st\n",
    "\n",
    "        \n",
    "    # print('Frozen Lake ' + option + ' - Value Iteration')\n",
    "    # print(list_scores)\n",
    "    \n",
    "    plt.plot(gamma_arr, time_array)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.title('Frozen Lake ' + option + ' - Value Iteration - Execution Time Analysis')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(gamma_arr,list_scores)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.ylabel('Average Rewards')\n",
    "    plt.title('Frozen Lake ' + option + ' - Value Iteration - Reward Analysis')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(gamma_arr,iters)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.ylabel('Iterations to Converge')\n",
    "    plt.title('Frozen Lake ' + option + ' - Value Iteration - Convergence Analysis')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(gamma_arr,best_vals)\n",
    "    plt.xlabel('Gammas')\n",
    "    plt.ylabel('Optimal Value')\n",
    "    plt.legend(['epsilon=0.05','epsilon=0.15','epsilon=0.25','epsilon=0.50','epsilon=0.75','epsilon=0.95'])\n",
    "    plt.title('Frozen Lake ' + option + ' - Value Iteration - Best Value Analysis')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    ### Q-LEARNING #####\n",
    "    print('Q LEARNING WITH FROZEN LAKE ' + option)\n",
    "    st = time.time()\n",
    "    reward_array = []\n",
    "    iter_array = []\n",
    "    size_array = []\n",
    "    chunks_array = []\n",
    "    averages_array = []\n",
    "    time_array = []\n",
    "    Q_array = []\n",
    "    for epsilon in [0.05,0.15,0.25,0.5,0.75,0.90]:\n",
    "        Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "        rewards = []\n",
    "        iters = []\n",
    "        optimal=[0]*env.observation_space.n\n",
    "        alpha = 0.85\n",
    "        gamma = 0.95\n",
    "        episodes = 30000\n",
    "        \n",
    "        if (option == \"4x4\"):\n",
    "            environment  = 'FrozenLake-v1'\n",
    "            env = gym.make(environment)\n",
    "        else:\n",
    "            env = FrozenLakeEnv(desc=MAPS[\"20x20\"])\n",
    "\n",
    "        env = env.unwrapped\n",
    "        desc = env.unwrapped.desc\n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            t_reward = 0\n",
    "            max_steps = 1000000\n",
    "            for i in range(max_steps):\n",
    "                if done:\n",
    "                    break        \n",
    "                current = state\n",
    "                if np.random.rand() < (epsilon):\n",
    "                    action = np.argmax(Q[current, :])\n",
    "                else:\n",
    "                    action = env.action_space.sample()\n",
    "                \n",
    "                state, reward, done, info = env.step(action)\n",
    "                t_reward += reward\n",
    "                Q[current, action] += alpha * (reward + gamma * np.max(Q[state, :]) - Q[current, action])\n",
    "            epsilon=(1-2.71**(-episode/1000))\n",
    "            rewards.append(t_reward)\n",
    "            iters.append(i)\n",
    "\n",
    "\n",
    "        for k in range(env.observation_space.n):\n",
    "            optimal[k]=np.argmax(Q[k, :])\n",
    "\n",
    "        reward_array.append(rewards)\n",
    "        iter_array.append(iters)\n",
    "        Q_array.append(Q)\n",
    "\n",
    "        env.close()\n",
    "        end=time.time()\n",
    "        time_array.append(end-st)\n",
    "\n",
    "        # Plot results\n",
    "        def chunk_list(l, n):\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i + n]\n",
    "\n",
    "        size = int(episodes / 50)\n",
    "        chunks = list(chunk_list(rewards, size))\n",
    "        averages = [sum(chunk) / len(chunk) for chunk in chunks]\n",
    "        size_array.append(size)\n",
    "        chunks_array.append(chunks)\n",
    "        averages_array.append(averages)\n",
    "        \n",
    "    # print('Frozen Lake ' + option + ' - Q Learning Q Array')\n",
    "    # print(Q_array)\n",
    "\n",
    "    # print('Frozen Lake ' + option + ' - Q Learning Reward Array')\n",
    "    # print(reward_array)\n",
    "\n",
    "    plt.plot(range(0, len(reward_array[0]), size_array[0]), averages_array[0],label='epsilon=0.05')\n",
    "    plt.plot(range(0, len(reward_array[1]), size_array[1]), averages_array[1],label='epsilon=0.15')\n",
    "    plt.plot(range(0, len(reward_array[2]), size_array[2]), averages_array[2],label='epsilon=0.25')\n",
    "    plt.plot(range(0, len(reward_array[3]), size_array[3]), averages_array[3],label='epsilon=0.50')\n",
    "    plt.plot(range(0, len(reward_array[4]), size_array[4]), averages_array[4],label='epsilon=0.75')\n",
    "    plt.plot(range(0, len(reward_array[5]), size_array[5]), averages_array[5],label='epsilon=0.95')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.grid()\n",
    "    plt.title('Frozen Lake ' + option + ' - Q Learning - Constant Epsilon')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot([0.05,0.15,0.25,0.5,0.75,0.95],time_array)\n",
    "    plt.xlabel('Epsilon Values')\n",
    "    plt.grid()\n",
    "    plt.title('Frozen Lake ' + option + ' - Q Learning')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(1,6,1)\n",
    "    plt.imshow(Q_array[0])\n",
    "    plt.title('Epsilon=0.05')\n",
    "\n",
    "    plt.subplot(1,6,2)\n",
    "    plt.title('Epsilon=0.15')\n",
    "    plt.imshow(Q_array[1])\n",
    "\n",
    "    plt.subplot(1,6,3)\n",
    "    plt.title('Epsilon=0.25')\n",
    "    plt.imshow(Q_array[2])\n",
    "\n",
    "    plt.subplot(1,6,4)\n",
    "    plt.title('Epsilon=0.50')\n",
    "    plt.imshow(Q_array[3])\n",
    "\n",
    "    plt.subplot(1,6,5)\n",
    "    plt.title('Epsilon=0.75')\n",
    "    plt.imshow(Q_array[4])\n",
    "\n",
    "    plt.subplot(1,6,6)\n",
    "    plt.title('Epsilon=0.95')\n",
    "    plt.imshow(Q_array[5])\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f7f52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors():\n",
    "    return {\n",
    "        b'S': 'green',\n",
    "        b'F': 'skyblue',\n",
    "        b'H': 'black',\n",
    "        b'G': 'gold',\n",
    "    }\n",
    "\n",
    "def directions():\n",
    "    return {\n",
    "        3: '⬆',\n",
    "        2: '➡',\n",
    "        1: '⬇',\n",
    "        0: '⬅'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac105f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FROZEN LAKE 4X4\n",
      "POLICY ITERATION WITH FROZEN LAKE 4x4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FrozenLakeEnv' object has no attribute 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HUANGP~1\\AppData\\Local\\Temp/ipykernel_53096/1275638633.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'STARTING FROZEN LAKE 4X4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_Frozen_Lake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"4x4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HUANGP~1\\AppData\\Local\\Temp/ipykernel_53096/4116752478.py\u001b[0m in \u001b[0;36mrun_Frozen_Lake\u001b[1;34m(option)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mbest_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_policy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_policy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshow_policy_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frozen Lake  '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moption\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Policy Map Iteration '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' (Policy Iteration) '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'i: '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdirections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HUANGP~1\\AppData\\Local\\Temp/ipykernel_53096/3703240317.py\u001b[0m in \u001b[0;36mrun_policy_iteration\u001b[1;34m(env, gamma)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_policy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mmax_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FrozenLakeEnv' object has no attribute 'env'"
     ]
    }
   ],
   "source": [
    "print('STARTING FROZEN LAKE 4X4')\n",
    "run_Frozen_Lake(\"4x4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('STARTING FROZEN LAKE 20X20')\n",
    "run_Frozen_Lake(\"20x20\")\n",
    "print('END OF RUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in glob.glob(\"/kaggle/working/*.png\"):\n",
    "    img = mpimg.imread(image_path)\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.axis('off') \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7490b",
   "metadata": {},
   "source": [
    "Forest Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89f41ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, R = forest(S=400, r1=5, r2= 2, p=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32899dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e759f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(P, R, policy, test_count=100, gamma=0.9):\n",
    "    num_state = P.shape[-1]\n",
    "    total_episode = num_state * test_count\n",
    "    # start in each state\n",
    "    total_reward = 0\n",
    "    for state in range(num_state):\n",
    "        state_reward = 0\n",
    "        for state_episode in range(test_count):\n",
    "            episode_reward = 0\n",
    "            disc_rate = 1\n",
    "            while True:\n",
    "                # take step\n",
    "                action = policy[state]\n",
    "                # get next step using P\n",
    "                probs = P[action][state]\n",
    "                candidates = list(range(len(P[action][state])))\n",
    "                next_state =  choice(candidates, 1, p=probs)[0]\n",
    "                # get the reward\n",
    "                reward = R[state][action] * disc_rate\n",
    "                episode_reward += reward\n",
    "                # when go back to 0 ended\n",
    "                disc_rate *= gamma\n",
    "                if next_state == 0:\n",
    "                    break\n",
    "            state_reward += episode_reward\n",
    "        total_reward += state_reward\n",
    "    return total_reward / total_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a175e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVI(P, R, discount=0.9, epsilon=[1e-9]):\n",
    "    vi_df = pd.DataFrame(columns=[\"Epsilon\", \"Policy\", \"Iteration\", \n",
    "                                  \"Time\", \"Reward\", \"Value Function\"])\n",
    "    for eps in epsilon:\n",
    "        vi = ValueIteration(P, R, gamma=discount, epsilon=eps, max_iter=int(1e15))\n",
    "        vi.run()\n",
    "        reward = test_policy(P, R, vi.policy)\n",
    "        info = [float(eps), vi.policy, vi.iter, vi.time, reward, vi.V]\n",
    "        df_length = len(vi_df)\n",
    "        vi_df.loc[df_length] = info\n",
    "    return vi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b47f9f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Time</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Value Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>1.063592</td>\n",
       "      <td>(4.692521349538996, 5.222508423648746, 5.22250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>1.060549</td>\n",
       "      <td>(4.711510693723443, 5.240342956300988, 5.24034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>153</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>1.065023</td>\n",
       "      <td>(4.711792200170572, 5.240612941282766, 5.24061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>213</td>\n",
       "      <td>0.048002</td>\n",
       "      <td>1.061844</td>\n",
       "      <td>(4.711792701376236, 5.240613431159993, 5.24061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>273</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>1.064212</td>\n",
       "      <td>(4.711792702272321, 5.240613432044941, 5.24061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>333</td>\n",
       "      <td>0.076017</td>\n",
       "      <td>1.064922</td>\n",
       "      <td>(4.711792702273928, 5.240613432046534, 5.24061...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epsilon                                             Policy Iteration  \\\n",
       "0  1.000000e-01  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...        53   \n",
       "1  1.000000e-03  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...        93   \n",
       "2  1.000000e-06  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       153   \n",
       "3  1.000000e-09  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       213   \n",
       "4  1.000000e-12  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       273   \n",
       "5  1.000000e-15  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       333   \n",
       "\n",
       "       Time    Reward                                     Value Function  \n",
       "0  0.016012  1.063592  (4.692521349538996, 5.222508423648746, 5.22250...  \n",
       "1  0.021005  1.060549  (4.711510693723443, 5.240342956300988, 5.24034...  \n",
       "2  0.033998  1.065023  (4.711792200170572, 5.240612941282766, 5.24061...  \n",
       "3  0.048002  1.061844  (4.711792701376236, 5.240613431159993, 5.24061...  \n",
       "4  0.066014  1.064212  (4.711792702272321, 5.240613432044941, 5.24061...  \n",
       "5  0.076017  1.064922  (4.711792702273928, 5.240613432046534, 5.24061...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_df = trainVI(P, R, epsilon=[1e-1, 1e-3, 1e-6, 1e-9, 1e-12, 1e-15])\n",
    "vi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b82c0327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4.484020948410034, 1.061362920552399)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = PolicyIteration(P, R, gamma=0.9, max_iter=1e6)\n",
    "pi.run()\n",
    "pi_pol = pi.policy\n",
    "pi_reward = test_policy(P, R, pi_pol)\n",
    "pi_iter = pi.iter\n",
    "pi_time = pi.time\n",
    "pi_iter, pi_time, pi_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64bb3f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(pi_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96221f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainQ(P, R, discount=0.9, alpha_dec=[0.99], alpha_min=[0.001], \n",
    "            epsilon=[1.0], epsilon_decay=[0.99], n_iter=[1000000]):\n",
    "    q_df = pd.DataFrame(columns=[\"Iterations\", \"Alpha Decay\", \"Alpha Min\", \n",
    "                                 \"Epsilon\", \"Epsilon Decay\", \"Reward\",\n",
    "                                 \"Time\", \"Policy\", \"Value Function\",\n",
    "                                 \"Training Rewards\"])\n",
    "    \n",
    "    count = 0\n",
    "    for i in n_iter:\n",
    "        for eps in epsilon:\n",
    "            for eps_dec in epsilon_decay:\n",
    "                for a_dec in alpha_dec:\n",
    "                    for a_min in alpha_min:\n",
    "                        q = QLearning(P, R, discount, alpha_decay=a_dec, \n",
    "                                      alpha_min=a_min, epsilon=eps, \n",
    "                                      epsilon_decay=eps_dec, n_iter=i)\n",
    "                        q.run()\n",
    "                        reward = test_policy(P, R, q.policy)\n",
    "                        count += 1\n",
    "                        print(\"{}: {}\".format(count, reward))\n",
    "                        st = q.run_stats\n",
    "                        rews = [s['Reward'] for s in st]\n",
    "                        info = [i, a_dec, a_min, eps, eps_dec, reward, \n",
    "                                q.time, q.policy, q.V, rews]\n",
    "                        \n",
    "                        df_length = len(q_df)\n",
    "                        q_df.loc[df_length] = info\n",
    "    return q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd2db381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.9161910066949593\n",
      "2: 0.9767941022374209\n",
      "3: 0.9254969288953744\n",
      "4: 0.9430497642808974\n",
      "5: 0.9489591837294816\n",
      "6: 0.9656097037620972\n",
      "7: 0.9256514893915386\n",
      "8: 0.949778613973109\n",
      "9: 0.8225\n",
      "10: 0.9722146271233436\n",
      "11: 0.8325\n",
      "12: 0.9406892044567281\n",
      "13: 0.9576459392598914\n",
      "14: 0.9470985258014766\n",
      "15: 0.9500819638017783\n",
      "16: 0.9354461528096237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HUANGP~1\\AppData\\Local\\Temp/ipykernel_53096/2019271284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m q_df = trainQ(P, R, discount=0.9, alpha_dec=alpha_decs, alpha_min=alpha_mins, \n\u001b[1;32m----> 7\u001b[1;33m             epsilon=eps, epsilon_decay=eps_dec, n_iter=iters)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HUANGP~1\\AppData\\Local\\Temp/ipykernel_53096/762159192.py\u001b[0m in \u001b[0;36mtrainQ\u001b[1;34m(P, R, discount, alpha_dec, alpha_min, epsilon, epsilon_decay, n_iter)\u001b[0m\n\u001b[0;32m     15\u001b[0m                                       \u001b[0malpha_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                       epsilon_decay=eps_dec, n_iter=i)\n\u001b[1;32m---> 17\u001b[1;33m                         \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\hiive\\mdptoolbox\\mdp.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;31m# compute the value function and the policy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     38\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     39\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha_decs = [0.99, 0.999]\n",
    "alpha_mins =[0.001, 0.0001]\n",
    "eps = [10.0, 1.0]\n",
    "eps_dec = [0.99, 0.999]\n",
    "iters = [1000000, 10000000]\n",
    "q_df = trainQ(P, R, discount=0.9, alpha_dec=alpha_decs, alpha_min=alpha_mins, \n",
    "            epsilon=eps, epsilon_decay=eps_dec, n_iter=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf6ea0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "5    True\n",
       "Name: Policy, dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_df.Policy == pi_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0289edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.915"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_policy(P,R,q_df.Policy[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c138772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Alpha Decay</th>\n",
       "      <th>Alpha Min</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Epsilon Decay</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Time</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Value Function</th>\n",
       "      <th>Training Rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.650183</td>\n",
       "      <td>79.101158</td>\n",
       "      <td>(0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712210801507589, 5.241277084192105, 5.24121...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.636374</td>\n",
       "      <td>81.331570</td>\n",
       "      <td>(0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>(4.672188906786895, 5.200874840421224, 4.37178...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.607256</td>\n",
       "      <td>79.836893</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>(4.711828804944402, 5.241218072985039, 5.24151...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.611782</td>\n",
       "      <td>78.991840</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>(4.710461366899375, 5.239581376346029, 5.09524...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.577487</td>\n",
       "      <td>78.822786</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>(4.71057876795351, 5.240113535858624, 5.240027...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.673996</td>\n",
       "      <td>78.826639</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>(4.666537393022336, 5.1952190427092955, 4.3410...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.627861</td>\n",
       "      <td>78.541732</td>\n",
       "      <td>(0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.713478207004994, 5.242419702750562, 5.24130...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.626661</td>\n",
       "      <td>78.696460</td>\n",
       "      <td>(0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>(4.708203589152052, 5.237402752385588, 5.13867...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.529701</td>\n",
       "      <td>79.151859</td>\n",
       "      <td>(0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>(4.711667962492642, 5.240921762076372, 5.24098...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.655280</td>\n",
       "      <td>78.428780</td>\n",
       "      <td>(0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>(4.67205487152553, 5.200652330776339, 4.374608...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.660154</td>\n",
       "      <td>78.675761</td>\n",
       "      <td>(0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>(4.711025191486715, 5.2417068541995695, 5.2414...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.608397</td>\n",
       "      <td>78.833787</td>\n",
       "      <td>(0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>(4.7108507790137235, 5.23987409302481, 4.07502...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.679083</td>\n",
       "      <td>78.631743</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.710746635650406, 5.239945116261988, 5.23961...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.685060</td>\n",
       "      <td>78.638763</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.667488627353147, 5.196107070776506, 4.34537...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>78.396698</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>(4.710578331571543, 5.239824592380612, 5.24129...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 15.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.676218</td>\n",
       "      <td>79.069843</td>\n",
       "      <td>(0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.709634116539802, 5.238128004597249, 5.14274...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.713520</td>\n",
       "      <td>758.962483</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.713456716555401, 5.241818243139722, 5.24195...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.811776</td>\n",
       "      <td>753.368077</td>\n",
       "      <td>(0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712028223290521, 5.240617676419864, 5.24053...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.764109</td>\n",
       "      <td>758.753293</td>\n",
       "      <td>(0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>(4.711813143171199, 5.2408553873821315, 5.2409...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.765968</td>\n",
       "      <td>757.409990</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.7122968228556275, 5.24058759829393, 5.24056...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.740316</td>\n",
       "      <td>759.262408</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712765935275721, 5.240442925278157, 5.24095...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.861893</td>\n",
       "      <td>754.118247</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.7110413199876495, 5.240350747703233, 5.2404...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.656581</td>\n",
       "      <td>763.279314</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712531622602435, 5.241278709113563, 5.24094...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.832774</td>\n",
       "      <td>756.243727</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712419345524845, 5.241214503791765, 5.24109...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.812239</td>\n",
       "      <td>757.430995</td>\n",
       "      <td>(0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712619094570865, 5.241285026183231, 5.23961...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.775658</td>\n",
       "      <td>754.550344</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.712633531083751, 5.241305643065199, 5.24086...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.775596</td>\n",
       "      <td>763.908457</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.710290054198275, 5.2392387264905755, 5.2400...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.787110</td>\n",
       "      <td>759.147388</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.7115531494708645, 5.240621650939948, 5.2406...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.753036</td>\n",
       "      <td>760.987789</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.709471191597694, 5.23907146443661, 5.240876...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.850376</td>\n",
       "      <td>754.245517</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.7113925744631375, 5.240062151463515, 5.2408...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.755612</td>\n",
       "      <td>761.110826</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.706376842199095, 5.2368824168828, 5.2384833...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.851437</td>\n",
       "      <td>754.322284</td>\n",
       "      <td>(0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>(4.711772023516413, 5.240409679013809, 5.24095...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iterations  Alpha Decay  Alpha Min  Epsilon  Epsilon Decay    Reward  \\\n",
       "0     1000000        0.990     0.0010     10.0          0.990  2.650183   \n",
       "1     1000000        0.990     0.0001     10.0          0.990  2.636374   \n",
       "2     1000000        0.999     0.0010     10.0          0.990  2.607256   \n",
       "3     1000000        0.999     0.0001     10.0          0.990  2.611782   \n",
       "4     1000000        0.990     0.0010     10.0          0.999  2.577487   \n",
       "5     1000000        0.990     0.0001     10.0          0.999  2.673996   \n",
       "6     1000000        0.999     0.0010     10.0          0.999  2.627861   \n",
       "7     1000000        0.999     0.0001     10.0          0.999  2.626661   \n",
       "8     1000000        0.990     0.0010      1.0          0.990  2.529701   \n",
       "9     1000000        0.990     0.0001      1.0          0.990  2.655280   \n",
       "10    1000000        0.999     0.0010      1.0          0.990  2.660154   \n",
       "11    1000000        0.999     0.0001      1.0          0.990  2.608397   \n",
       "12    1000000        0.990     0.0010      1.0          0.999  2.679083   \n",
       "13    1000000        0.990     0.0001      1.0          0.999  2.685060   \n",
       "14    1000000        0.999     0.0010      1.0          0.999  0.822000   \n",
       "15    1000000        0.999     0.0001      1.0          0.999  2.676218   \n",
       "16   10000000        0.990     0.0010     10.0          0.990  2.713520   \n",
       "17   10000000        0.990     0.0001     10.0          0.990  2.811776   \n",
       "18   10000000        0.999     0.0010     10.0          0.990  2.764109   \n",
       "19   10000000        0.999     0.0001     10.0          0.990  2.765968   \n",
       "20   10000000        0.990     0.0010     10.0          0.999  2.740316   \n",
       "21   10000000        0.990     0.0001     10.0          0.999  2.861893   \n",
       "22   10000000        0.999     0.0010     10.0          0.999  2.656581   \n",
       "23   10000000        0.999     0.0001     10.0          0.999  2.832774   \n",
       "24   10000000        0.990     0.0010      1.0          0.990  2.812239   \n",
       "25   10000000        0.990     0.0001      1.0          0.990  2.775658   \n",
       "26   10000000        0.999     0.0010      1.0          0.990  2.775596   \n",
       "27   10000000        0.999     0.0001      1.0          0.990  2.787110   \n",
       "28   10000000        0.990     0.0010      1.0          0.999  2.753036   \n",
       "29   10000000        0.990     0.0001      1.0          0.999  2.850376   \n",
       "30   10000000        0.999     0.0010      1.0          0.999  2.755612   \n",
       "31   10000000        0.999     0.0001      1.0          0.999  2.851437   \n",
       "\n",
       "          Time                                             Policy  \\\n",
       "0    79.101158  (0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "1    81.331570  (0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "2    79.836893  (0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, ...   \n",
       "3    78.991840  (0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, ...   \n",
       "4    78.822786  (0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, ...   \n",
       "5    78.826639  (0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...   \n",
       "6    78.541732  (0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7    78.696460  (0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...   \n",
       "8    79.151859  (0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...   \n",
       "9    78.428780  (0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, ...   \n",
       "10   78.675761  (0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "11   78.833787  (0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "12   78.631743  (0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13   78.638763  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14   78.396698  (0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "15   79.069843  (0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...   \n",
       "16  758.962483  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "17  753.368077  (0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "18  758.753293  (0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...   \n",
       "19  757.409990  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "20  759.262408  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "21  754.118247  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "22  763.279314  (0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "23  756.243727  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "24  757.430995  (0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "25  754.550344  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "26  763.908457  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "27  759.147388  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "28  760.987789  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "29  754.245517  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "30  761.110826  (0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "31  754.322284  (0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                       Value Function  \\\n",
       "0   (4.712210801507589, 5.241277084192105, 5.24121...   \n",
       "1   (4.672188906786895, 5.200874840421224, 4.37178...   \n",
       "2   (4.711828804944402, 5.241218072985039, 5.24151...   \n",
       "3   (4.710461366899375, 5.239581376346029, 5.09524...   \n",
       "4   (4.71057876795351, 5.240113535858624, 5.240027...   \n",
       "5   (4.666537393022336, 5.1952190427092955, 4.3410...   \n",
       "6   (4.713478207004994, 5.242419702750562, 5.24130...   \n",
       "7   (4.708203589152052, 5.237402752385588, 5.13867...   \n",
       "8   (4.711667962492642, 5.240921762076372, 5.24098...   \n",
       "9   (4.67205487152553, 5.200652330776339, 4.374608...   \n",
       "10  (4.711025191486715, 5.2417068541995695, 5.2414...   \n",
       "11  (4.7108507790137235, 5.23987409302481, 4.07502...   \n",
       "12  (4.710746635650406, 5.239945116261988, 5.23961...   \n",
       "13  (4.667488627353147, 5.196107070776506, 4.34537...   \n",
       "14  (4.710578331571543, 5.239824592380612, 5.24129...   \n",
       "15  (4.709634116539802, 5.238128004597249, 5.14274...   \n",
       "16  (4.713456716555401, 5.241818243139722, 5.24195...   \n",
       "17  (4.712028223290521, 5.240617676419864, 5.24053...   \n",
       "18  (4.711813143171199, 5.2408553873821315, 5.2409...   \n",
       "19  (4.7122968228556275, 5.24058759829393, 5.24056...   \n",
       "20  (4.712765935275721, 5.240442925278157, 5.24095...   \n",
       "21  (4.7110413199876495, 5.240350747703233, 5.2404...   \n",
       "22  (4.712531622602435, 5.241278709113563, 5.24094...   \n",
       "23  (4.712419345524845, 5.241214503791765, 5.24109...   \n",
       "24  (4.712619094570865, 5.241285026183231, 5.23961...   \n",
       "25  (4.712633531083751, 5.241305643065199, 5.24086...   \n",
       "26  (4.710290054198275, 5.2392387264905755, 5.2400...   \n",
       "27  (4.7115531494708645, 5.240621650939948, 5.2406...   \n",
       "28  (4.709471191597694, 5.23907146443661, 5.240876...   \n",
       "29  (4.7113925744631375, 5.240062151463515, 5.2408...   \n",
       "30  (4.706376842199095, 5.2368824168828, 5.2384833...   \n",
       "31  (4.711772023516413, 5.240409679013809, 5.24095...   \n",
       "\n",
       "                                     Training Rewards  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "4   [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, ...  \n",
       "5   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "6   [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...  \n",
       "7   [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "11  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "12  [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "14  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 15.0, 0.0, 0.0,...  \n",
       "15  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "16  [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "19  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "21  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "22  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "23  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "24  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "26  [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "27  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "29  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "30  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "31  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f67d5b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha Decay</th>\n",
       "      <th>Alpha Min</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Epsilon Decay</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iterations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>2.520468</td>\n",
       "      <td>78.998520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000000</th>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>2.781750</td>\n",
       "      <td>757.943821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Alpha Decay  Alpha Min  Epsilon  Epsilon Decay    Reward  \\\n",
       "Iterations                                                             \n",
       "1000000          0.9945    0.00055      5.5         0.9945  2.520468   \n",
       "10000000         0.9945    0.00055      5.5         0.9945  2.781750   \n",
       "\n",
       "                  Time  \n",
       "Iterations              \n",
       "1000000      78.998520  \n",
       "10000000    757.943821  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df.groupby(\"Iterations\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a731299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha Decay</th>\n",
       "      <th>Alpha Min</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epsilon Decay</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.990</th>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.697819</td>\n",
       "      <td>418.617667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.604399</td>\n",
       "      <td>418.324673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Alpha Decay  Alpha Min  Epsilon    Reward        Time\n",
       "Epsilon Decay                                                       \n",
       "0.990               0.9945    0.00055      5.5  2.697819  418.617667\n",
       "0.999               0.9945    0.00055      5.5  2.604399  418.324673"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df.groupby(\"Epsilon Decay\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b215ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
